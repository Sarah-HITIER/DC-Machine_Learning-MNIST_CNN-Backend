{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD/TP 1 : MNIST et Convolutional Neural Network\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Notre premier notebook pour le deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 1. Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\python310\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in c:\\python310\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python310\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python310\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 2. Chargement du dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"../data/raw\", download=True, train=True, transform=tf), batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"../data/raw\", download=True, train=False, transform=tf), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x = batch[0][:10]\n",
    "y = batch[1][:10]\n",
    "\n",
    "# Display images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x[i].numpy().squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f\"Digit: {y[i].item()}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 3. Construction d‚Äôun mod√®le de convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=160, out_features=50, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernels, output_size):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=n_kernels, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Fully connected layers\n",
    "            nn.Flatten(),\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=n_kernels * 4 * 4, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=50, out_features=output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Init params\n",
    "input_size = 28*28\n",
    "n_kernels = 10\n",
    "output_size = 10\n",
    "\n",
    "# Create model\n",
    "model = ConvNet(input_size, n_kernels, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 4. Construction du train et du test.\n",
    "##### 3. 4. 1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, perm=torch.arange(0, 784).long(), n_epoch=1): # prendre en param√®tre un mod√®le, une perm avec une valeur par d√©faut fix√©e √† torch.arange(0, 784).long() et le nombre d‚Äôepoch (n_epoch) avec une valeur par d√©faut √† 1\n",
    "    # model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters()) # fixer un optimizer qui va ajuster automatiquement la valeur ùõæ qui est notre learning rate\n",
    "    \n",
    "    model.train()  # lancer l‚Äôentra√Ænement du mod√®le √† l‚Äôaide de model.train()\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1): # R√©diger une boucle for repr√©sentant le nombre d‚Äôit√©ration (epoch)\n",
    "        running_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader): # R√©diger une for imbriqu√© repr√©sentant l‚Äôit√©ration i qui d√©finit la i-√®me image du train_loader et un couple (data, target) repr√©sentant les valeurs de la matrice et la cible attendu.\n",
    "            data, target = data.to(device), target.to(device) # Envoyer les donn√©es vers la carte graphique : data, targets = data.to(device), target.to(device)\n",
    "            \n",
    "            # Appliquer les permutations de pixels par la matrice circulaire de Toeplitz\n",
    "            data = data.view(-1, 28*28)\n",
    "            data = data[:, perm]\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "            \n",
    "            optimizer.zero_grad() # Appliquer le step en appelant sur l‚Äôoptimizer la m√©thode zero_grad()\n",
    "            \n",
    "            logits = model(data) # pr√©diction sur data dont le r√©sultat sera stock√© dans la variable logits\n",
    "            \n",
    "            loss = F.cross_entropy(logits, target) # Calculer le loss √† l‚Äôaide de F.cross_entropy(), elle prends deux arguments.\n",
    "            \n",
    "            loss.backward() # Appliquer la mise √† jour des poids sur le loss avec la m√©thode backward()\n",
    "            \n",
    "            optimizer.step() # Appliquer la m√©thode step() sur l‚Äôoptimizer pour finaliser l‚Äôit√©ration d‚Äôun cycle d‚Äôapprentissage.\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0: # Afficher tout les 100-it√©ration le num√©ro de l‚Äôit√©ration, le num√©ro du step (correspondant au num√©ro de l‚Äôimage du train-loader) et la valeur du loss du mod√®le\n",
    "                print(f\"epoch={epoch}, step={batch_idx}: train loss={running_loss / 100:.4f}\")\n",
    "                running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 4. 2. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    # D‚Äôinitialiser deux variables test_loss et correct √† 0.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # model.to(device)\n",
    "\n",
    "    model.eval()  # pr√©parer le mod√®le √† l‚Äôinf√©rence.\n",
    "\n",
    "    for data, target in test_loader: # R√©diger une for imbriqu√© repr√©sentant l‚Äôit√©ration i qui d√©finit la i-√®me image du train_loader et un couple (data, target) repr√©sentant les valeurs de la matrice et la cible attendu.\n",
    "        data, target = data.to(device), target.to(device) # Envoyer les donn√©es vers la carte graphique : data, targets = data.to(device), target.to(device)\n",
    "            \n",
    "        # permutations de pixels par la matrice circulaire de Toeplitz.\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        \n",
    "        logits = model(data) # Lancer une pr√©diction √† l‚Äôaide de model(date) dont le r√©sultat sera stock√© dans la variable logits.\n",
    "        \n",
    "        test_loss += F.cross_entropy(logits, target, reduction='sum').item() # La variable test_loss va r√©aliser un algorithme de type map-reduce avec les √©l√©ments de logits par rapport au targets associ√© √† une r√©duction de somme. La fonction permettant cette t√¢che provient de F.cross_entropy() qui prend trois param√®tres.\n",
    "        \n",
    "        pred = logits.argmax(dim=1, keepdim=True)  # La variable pred va renvoyer la pr√©diction finale par la probabilit√© la plus haute parmis les 10 √©l√©ments de sorties possible. Nous utiliserons la fonction torch.argmax() qui prends en param√®tre le logits que l‚Äôon a d√©finit, et une dim=1 pour pr√©ciser que le tableau de logits et en dimension 1.\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item() # La variable correct qui va compter le nombre de pr√©diction correcte\n",
    "\n",
    "    # Calculer le loss et le taux d'accuracy\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    # Affichage des r√©sultats\n",
    "    print(f\"\\ntest loss={test_loss:.4f}, accuracy={accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 5. Lancement de l‚Äôentrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©placement du mod√®le\n",
    "# model.to(device)\n",
    "\n",
    "def main(model):    \n",
    "    # Affichage du nombre de param√®tres du mod√®le\n",
    "    print(f\"Parameters={sum(p.numel() for p in model.parameters())/1e3}K\")\n",
    "    \n",
    "    # Entra√Ænement du mod√®le\n",
    "    train(model)\n",
    "    \n",
    "    # √âvaluation du mod√®le sur le dataset de test\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage du mod√®le ConvNet :\n",
      "ConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=96, out_features=50, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Lancement de l'entra√Ænement et de l'√©valuation :\n",
      "Parameters=6.422K\n",
      "epoch=1, step=0: train loss=0.0233\n",
      "epoch=1, step=100: train loss=1.3753\n",
      "epoch=1, step=200: train loss=0.4426\n",
      "epoch=1, step=300: train loss=0.3349\n",
      "epoch=1, step=400: train loss=0.2884\n",
      "epoch=1, step=500: train loss=0.2362\n",
      "epoch=1, step=600: train loss=0.2242\n",
      "epoch=1, step=700: train loss=0.2016\n",
      "epoch=1, step=800: train loss=0.1615\n",
      "epoch=1, step=900: train loss=0.1630\n",
      "\n",
      "test loss=0.1292, accuracy=0.9620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# D√©finition des param√®tres\n",
    "n_kernels = 6\n",
    "input_size = 28*28  # Taille d'entr√©e (nombre de canaux de l'image en niveaux de gris)\n",
    "output_size = 10  # Nombre de classes de sortie (chiffres de 0 √† 9)\n",
    "\n",
    "# Initialisation du mod√®le ConvNet\n",
    "convnets = ConvNet(input_size, n_kernels, output_size)\n",
    "convnets.to(device)\n",
    "\n",
    "# Affichage du mod√®le ConvNet\n",
    "print(\"Affichage du mod√®le ConvNet :\")\n",
    "print(convnets)\n",
    "\n",
    "# Lancement de l'entra√Ænement et de l'√©valuation\n",
    "print(\"Lancement de l'entra√Ænement et de l'√©valuation :\")\n",
    "main(convnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 6. Nouveau mod√®le : le perceptron multi-couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPerc(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(MultiPerc, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=input_size, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=n_hidden, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            # Third linear layer\n",
    "            nn.Linear(in_features=n_hidden, out_features=output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage du mod√®le MultiPerc :\n",
      "MultiPerc(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "Lancement de l'entra√Ænement et de l'√©valuation :\n",
      "Parameters=6.424K\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Lancement de l'entra√Ænement et de l'√©valuation\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLancement de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentra√Ænement et de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m√©valuation :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Entra√Ænement du mod√®le\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# √âvaluation du mod√®le sur le dataset de test\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test(model)\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, perm, n_epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Appliquer la mise √† jour des poids sur le loss avec la m√©thode backward()\u001b[39;00m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Appliquer la m√©thode step() sur l‚Äôoptimizer pour finaliser l‚Äôit√©ration d‚Äôun cycle d‚Äôapprentissage.\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# Afficher tout les 100-it√©ration le num√©ro de l‚Äôit√©ration, le num√©ro du step (correspondant au num√©ro de l‚Äôimage du train-loader) et la valeur du loss du mod√®le\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, step=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# D√©finition des param√®tres\n",
    "input_size = 28*28\n",
    "n_hidden = 8\n",
    "output_size = 8\n",
    "\n",
    "# Initialisation du mod√®le MultiPerc\n",
    "mlp = MultiPerc(input_size, n_hidden, output_size)\n",
    "# model.to(device)\n",
    "mlp.to(device)\n",
    "\n",
    "# Affichage du mod√®le MultiPerc\n",
    "print(\"Affichage du mod√®le MultiPerc :\")\n",
    "print(mlp)\n",
    "\n",
    "# Lancement de l'entra√Ænement et de l'√©valuation\n",
    "print(\"Lancement de l'entra√Ænement et de l'√©valuation :\")\n",
    "main(mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de l'entra√Ænement et de l'√©valuation :\n",
      "Parameters=6.424K\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lancement de l'entra√Ænement et de l'√©valuation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLancement de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentra√Ænement et de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m√©valuation :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Entra√Ænement du mod√®le\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# √âvaluation du mod√®le sur le dataset de test\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test(model)\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, perm, n_epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader): \u001b[38;5;66;03m# R√©diger une for imbriqu√© repr√©sentant l‚Äôit√©ration i qui d√©finit la i-√®me image du train_loader et un couple (data, target) repr√©sentant les valeurs de la matrice et la cible attendu.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, target\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# Envoyer les donn√©es vers la carte graphique : data, targets = data.to(device), target.to(device)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Appliquer les permutations de pixels par la matrice circulaire de Toeplitz\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Lancement de l'entra√Ænement et de l'√©valuation\n",
    "print(\"Lancement de l'entra√Ænement et de l'√©valuation :\")\n",
    "main(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp\n",
    "del convnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 7. Nouveau mod√®le : le perceptron multi-couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
