{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD/TP 1 : MNIST et Convolutional Neural Network\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Notre premier notebook pour le deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 1. Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: torch in c:\\python310\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (0.18.1)\n",
      "Requirement already satisfied: torchaudio in c:\\python310\\lib\\site-packages (2.3.1+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python310\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\python310\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\python310\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python310\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\python310\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\sarah\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 2. Chargement du dataset MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"../data/raw\", download=True, train=True, transform=tf), batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"../data/raw\", download=True, train=False, transform=tf), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x = batch[0][:10]\n",
    "y = batch[1][:10]\n",
    "\n",
    "# Display images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(x[i].numpy().squeeze(), cmap='gray')\n",
    "    axes[i].set_title(f\"Digit: {y[i].item()}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 3. Construction d’un modèle de convolution neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(10, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=160, out_features=50, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernels, output_size):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=n_kernels, out_channels=n_kernels, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Fully connected layers\n",
    "            nn.Flatten(),\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=n_kernels * 4 * 4, out_features=50),\n",
    "            nn.ReLU(),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=50, out_features=output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Init params\n",
    "input_size = 28*28\n",
    "n_kernels = 10\n",
    "output_size = 10\n",
    "\n",
    "# Create model\n",
    "model = ConvNet(input_size, n_kernels, output_size)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 4. Construction du train et du test.\n",
    "##### 3. 4. 1. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, perm=torch.arange(0, 784).long(), n_epoch=1): # prendre en paramètre un modèle, une perm avec une valeur par défaut fixée à torch.arange(0, 784).long() et le nombre d’epoch (n_epoch) avec une valeur par défaut à 1\n",
    "    # model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters()) # fixer un optimizer qui va ajuster automatiquement la valeur 𝛾 qui est notre learning rate\n",
    "    \n",
    "    model.train()  # lancer l’entraînement du modèle à l’aide de model.train()\n",
    "\n",
    "    for epoch in range(1, n_epoch + 1): # Rédiger une boucle for représentant le nombre d’itération (epoch)\n",
    "        running_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader): # Rédiger une for imbriqué représentant l’itération i qui définit la i-ème image du train_loader et un couple (data, target) représentant les valeurs de la matrice et la cible attendu.\n",
    "            data, target = data.to(device), target.to(device) # Envoyer les données vers la carte graphique : data, targets = data.to(device), target.to(device)\n",
    "            \n",
    "            # Appliquer les permutations de pixels par la matrice circulaire de Toeplitz\n",
    "            data = data.view(-1, 28*28)\n",
    "            data = data[:, perm]\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "            \n",
    "            optimizer.zero_grad() # Appliquer le step en appelant sur l’optimizer la méthode zero_grad()\n",
    "            \n",
    "            logits = model(data) # prédiction sur data dont le résultat sera stocké dans la variable logits\n",
    "            \n",
    "            loss = F.cross_entropy(logits, target) # Calculer le loss à l’aide de F.cross_entropy(), elle prends deux arguments.\n",
    "            \n",
    "            loss.backward() # Appliquer la mise à jour des poids sur le loss avec la méthode backward()\n",
    "            \n",
    "            optimizer.step() # Appliquer la méthode step() sur l’optimizer pour finaliser l’itération d’un cycle d’apprentissage.\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0: # Afficher tout les 100-itération le numéro de l’itération, le numéro du step (correspondant au numéro de l’image du train-loader) et la valeur du loss du modèle\n",
    "                print(f\"epoch={epoch}, step={batch_idx}: train loss={running_loss / 100:.4f}\")\n",
    "                running_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 4. 2. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    # D’initialiser deux variables test_loss et correct à 0.\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    # model.to(device)\n",
    "\n",
    "    model.eval()  # préparer le modèle à l’inférence.\n",
    "\n",
    "    for data, target in test_loader: # Rédiger une for imbriqué représentant l’itération i qui définit la i-ème image du train_loader et un couple (data, target) représentant les valeurs de la matrice et la cible attendu.\n",
    "        data, target = data.to(device), target.to(device) # Envoyer les données vers la carte graphique : data, targets = data.to(device), target.to(device)\n",
    "            \n",
    "        # permutations de pixels par la matrice circulaire de Toeplitz.\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        \n",
    "        logits = model(data) # Lancer une prédiction à l’aide de model(date) dont le résultat sera stocké dans la variable logits.\n",
    "        \n",
    "        test_loss += F.cross_entropy(logits, target, reduction='sum').item() # La variable test_loss va réaliser un algorithme de type map-reduce avec les éléments de logits par rapport au targets associé à une réduction de somme. La fonction permettant cette tâche provient de F.cross_entropy() qui prend trois paramètres.\n",
    "        \n",
    "        pred = logits.argmax(dim=1, keepdim=True)  # La variable pred va renvoyer la prédiction finale par la probabilité la plus haute parmis les 10 éléments de sorties possible. Nous utiliserons la fonction torch.argmax() qui prends en paramètre le logits que l’on a définit, et une dim=1 pour préciser que le tableau de logits et en dimension 1.\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item() # La variable correct qui va compter le nombre de prédiction correcte\n",
    "\n",
    "    # Calculer le loss et le taux d'accuracy\n",
    "    test_loss = test_loss/len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "\n",
    "    # Affichage des résultats\n",
    "    print(f\"\\ntest loss={test_loss:.4f}, accuracy={accuracy:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 5. Lancement de l’entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Déplacement du modèle\n",
    "# model.to(device)\n",
    "\n",
    "def main(model):    \n",
    "    # Affichage du nombre de paramètres du modèle\n",
    "    print(f\"Parameters={sum(p.numel() for p in model.parameters())/1e3}K\")\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    train(model)\n",
    "    \n",
    "    # Évaluation du modèle sur le dataset de test\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage du modèle ConvNet :\n",
      "ConvNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): Linear(in_features=96, out_features=50, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Linear(in_features=50, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Lancement de l'entraînement et de l'évaluation :\n",
      "Parameters=6.422K\n",
      "epoch=1, step=0: train loss=0.0233\n",
      "epoch=1, step=100: train loss=1.3753\n",
      "epoch=1, step=200: train loss=0.4426\n",
      "epoch=1, step=300: train loss=0.3349\n",
      "epoch=1, step=400: train loss=0.2884\n",
      "epoch=1, step=500: train loss=0.2362\n",
      "epoch=1, step=600: train loss=0.2242\n",
      "epoch=1, step=700: train loss=0.2016\n",
      "epoch=1, step=800: train loss=0.1615\n",
      "epoch=1, step=900: train loss=0.1630\n",
      "\n",
      "test loss=0.1292, accuracy=0.9620\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Définition des paramètres\n",
    "n_kernels = 6\n",
    "input_size = 28*28  # Taille d'entrée (nombre de canaux de l'image en niveaux de gris)\n",
    "output_size = 10  # Nombre de classes de sortie (chiffres de 0 à 9)\n",
    "\n",
    "# Initialisation du modèle ConvNet\n",
    "convnets = ConvNet(input_size, n_kernels, output_size)\n",
    "convnets.to(device)\n",
    "\n",
    "# Affichage du modèle ConvNet\n",
    "print(\"Affichage du modèle ConvNet :\")\n",
    "print(convnets)\n",
    "\n",
    "# Lancement de l'entraînement et de l'évaluation\n",
    "print(\"Lancement de l'entraînement et de l'évaluation :\")\n",
    "main(convnets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 6. Nouveau modèle : le perceptron multi-couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiPerc(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(MultiPerc, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=input_size, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=n_hidden, out_features=n_hidden),\n",
    "            nn.ReLU(),\n",
    "            # Third linear layer\n",
    "            nn.Linear(in_features=n_hidden, out_features=output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affichage du modèle MultiPerc :\n",
      "MultiPerc(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=8, bias=True)\n",
      "  )\n",
      ")\n",
      "Lancement de l'entraînement et de l'évaluation :\n",
      "Parameters=6.424K\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Lancement de l'entraînement et de l'évaluation\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLancement de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentraînement et de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mévaluation :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Évaluation du modèle sur le dataset de test\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test(model)\n",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, perm, n_epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# Appliquer la mise à jour des poids sur le loss avec la méthode backward()\u001b[39;00m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# Appliquer la méthode step() sur l’optimizer pour finaliser l’itération d’un cycle d’apprentissage.\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;66;03m# Afficher tout les 100-itération le numéro de l’itération, le numéro du step (correspondant au numéro de l’image du train-loader) et la valeur du loss du modèle\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, step=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: train loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrunning_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Définition des paramètres\n",
    "input_size = 28*28\n",
    "n_hidden = 8\n",
    "output_size = 8\n",
    "\n",
    "# Initialisation du modèle MultiPerc\n",
    "mlp = MultiPerc(input_size, n_hidden, output_size)\n",
    "# model.to(device)\n",
    "mlp.to(device)\n",
    "\n",
    "# Affichage du modèle MultiPerc\n",
    "print(\"Affichage du modèle MultiPerc :\")\n",
    "print(mlp)\n",
    "\n",
    "# Lancement de l'entraînement et de l'évaluation\n",
    "print(\"Lancement de l'entraînement et de l'évaluation :\")\n",
    "main(mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancement de l'entraînement et de l'évaluation :\n",
      "Parameters=6.424K\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Lancement de l'entraînement et de l'évaluation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLancement de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentraînement et de l\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mévaluation :\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p\u001b[38;5;241m.\u001b[39mnumel()\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1e3\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Évaluation du modèle sur le dataset de test\u001b[39;00m\n\u001b[0;32m     12\u001b[0m test(model)\n",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, perm, n_epoch)\u001b[0m\n\u001b[0;32m      8\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader): \u001b[38;5;66;03m# Rédiger une for imbriqué représentant l’itération i qui définit la i-ème image du train_loader et un couple (data, target) représentant les valeurs de la matrice et la cible attendu.\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, target\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;66;03m# Envoyer les données vers la carte graphique : data, targets = data.to(device), target.to(device)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Appliquer les permutations de pixels par la matrice circulaire de Toeplitz\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m28\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Lancement de l'entraînement et de l'évaluation\n",
    "print(\"Lancement de l'entraînement et de l'évaluation :\")\n",
    "main(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mlp\n",
    "del convnets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 7. Nouveau modèle : le perceptron multi-couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
