{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.391463Z",
     "start_time": "2024-06-25T07:27:07.212275Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "861b323771ae6647",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.448311Z",
     "start_time": "2024-06-25T07:27:10.392896Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device ='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcfceaa8f6da8b11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.458496Z",
     "start_time": "2024-06-25T07:27:10.449458Z"
    }
   },
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(), \n",
    "                         transforms.Normalize((0.1307,), (0.3081,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adc711c42a41e810",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.543879Z",
     "start_time": "2024-06-25T07:27:10.460042Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(datasets.MNIST(\"../data\", download=True, train=True, transform=tf), batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(datasets.MNIST(\"../data\", download=True, train=False, transform=tf), batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c1a5cbdd722b31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.569922Z",
     "start_time": "2024-06-25T07:27:10.545568Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "x = batch[0][:10]\n",
    "y = batch[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9fa6068c5d884a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.575437Z",
     "start_time": "2024-06-25T07:27:10.571154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7b34062120474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.580990Z",
     "start_time": "2024-06-25T07:27:10.577837Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5642a2351ca55f9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.919526Z",
     "start_time": "2024-06-25T07:27:10.582067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9EAAADiCAYAAABJNkTtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsbElEQVR4nO3deXxU9b3/8fckZAGExABJ2IJBQaAo+mAzoIIWxa0K4hXtVcGNqsEqYKn0VvB6rai4IILidQGxUv1JCVSl9GfZFAw72qIYFNkhYc0ikHW+9w9LLJ7v4JlkwmTmvJ6Px/zBO9858z3h883Md07yGZ8xxggAAAAAAPykmHBPAAAAAACASMEmGgAAAAAAl9hEAwAAAADgEptoAAAAAABcYhMNAAAAAIBLbKIBAAAAAHCJTTQAAAAAAC6xiQYAAAAAwCU20QAAAAAAuMQmup7btm2bfD6fnnnmmZAdc+nSpfL5fFq6dGnIjgnUFdYAvIz6h9exBuBl1H/9xSa6DsycOVM+n09r164N91TqxNy5czV06FC1b99ejRo10tlnn60xY8aosLAw3FNDPRHtayAvL0+jRo1Snz59lJiYKJ/Pp23btoV7Wqgnor3+f+yyyy6Tz+fTyJEjwz0V1BNeWQPvvvuusrKy1LhxYyUnJ6tPnz5avHhxuKeFMIv2+mcf8L0G4Z4AIs+IESPUqlUr3XLLLcrIyNA///lPTZ06VQsWLND69evVsGHDcE8RqFO5ubmaMmWKunTpos6dO+uzzz4L95SAsJg7d65yc3PDPQ3glHv00Uf12GOP6YYbbtDw4cNVUVGhjRs3avfu3eGeGlCn2Ad8j000gjZnzhz179//hKx79+4aNmyY3n77bd11113hmRhwilx77bUqLCxUkyZN9Mwzz7CJhieVlpZqzJgx+u1vf6vx48eHezrAKbNy5Uo99thjevbZZzVq1KhwTwc4pdgHfI9f5w6T8vJyjR8/Xt27d1dSUpIaN26siy66SEuWLAl4n+eff17t2rVTw4YN1a9fP23cuNEx5quvvtINN9yglJQUJSYmqkePHvrLX/7yk/M5evSovvrqKx04cOAnx/544UjS4MGDJUmbNm36yfsDUmSvgZSUFDVp0uQnxwGBRHL9H/f000/L7/froYcecn0f4LhIXgOTJ09Wenq6HnjgARlj9N133/3kfYB/F8n1zz7ge2yiw6S4uFivvfaa+vfvr6eeekqPPvqo9u/fr4EDB1qvas2aNUtTpkxRdna2xo0bp40bN+rSSy9VQUFB9ZgvvvhCF1xwgTZt2qSHH35Yzz77rBo3bqxBgwYpJyfnpPNZvXq1OnfurKlTp9bofPLz8yVJzZs3r9H94T3RtgaAYER6/e/YsUNPPvmknnrqKc/86h5CK5LXwKJFi9SzZ09NmTJFLVq0UJMmTdSyZUueP+BaJNe/jSf3AQYhN2PGDCPJrFmzJuCYyspKU1ZWdkJ2+PBhk5aWZu64447qbOvWrUaSadiwodm1a1d1vmrVKiPJjBo1qjr7+c9/bs455xxTWlpanfn9ftOnTx/ToUOH6mzJkiVGklmyZIkjmzBhQk1O2dx5550mNjbWbN68uUb3R3Tx0hqYNGmSkWS2bt0a1P0QvbxQ/zfccIPp06dP9b8lmezsbFf3RfSL5jVw6NAhI8k0a9bMnHbaaWbSpEnm3XffNVdccYWRZKZPn37S+yP6RXP9B+LFfQBXosMkNjZW8fHxkiS/369Dhw6psrJSPXr00Pr16x3jBw0apNatW1f/u1evXurdu7cWLFggSTp06JAWL16sG2+8USUlJTpw4IAOHDiggwcPauDAgfr6669P2uyif//+Msbo0UcfDfpcZs+erddff11jxoxRhw4dgr4/vCma1gAQrEiu/yVLlujPf/6zJk+eHNxJA/8mUtfA8V/dPnjwoF577TU99NBDuvHGG/Xhhx+qS5cuevzxx4P9VsCDIrX+bby6D2ATHUZvvvmmzj33XCUmJqpZs2Zq0aKFPvzwQxUVFTnG2oqyY8eO1R+r880338gYo0ceeUQtWrQ44TZhwgRJ0r59+0J+Dp988onuvPNODRw4UH/4wx9CfnxEt2hYA0BNRWL9V1ZW6te//rVuvfVW9ezZs9bHg7dF4ho4/ucLcXFxuuGGG6rzmJgYDR06VLt27dKOHTtq/TiIfpFY/z/m5X0A3bnD5I9//KOGDx+uQYMG6Te/+Y1SU1MVGxuriRMnasuWLUEfz+/3S5IeeughDRw40DrmrLPOqtWcf+zzzz/Xtddeq65du2rOnDlq0IBygnvRsAaAmorU+p81a5by8vL0yiuvOD4bvaSkRNu2bVNqaqoaNWpU68dCdIvUNXC8YVNycrJiY2NP+Fpqaqok6fDhw8rIyKj1YyF6RWr9/zuv7wO8dbb1yJw5c9S+fXvNnTtXPp+vOj/+btGPff31145s8+bNOuOMMyRJ7du3l/T9O6MDBgwI/YR/ZMuWLbriiiuUmpqqBQsW6LTTTqvzx0R0ifQ1ANRGpNb/jh07VFFRob59+zq+NmvWLM2aNUs5OTkaNGhQnc0B0SFS10BMTIzOO+88rVmzRuXl5dW/kitJe/bskSS1aNGizh4f0SFS6/849gH8OnfYHH/30hhTna1atUq5ubnW8fPmzTvhbxlWr16tVatW6corr5T0/buf/fv31yuvvKK9e/c67r9///6TzieY1vb5+fm6/PLLFRMTo7/97W88WaBGInkNALUVqfV/0003KScnx3GTpKuuuko5OTnq3bv3SY8BSJG7BiRp6NChqqqq0ptvvlmdlZaW6u2331aXLl3UqlWrnzwGvC2S6599wPe4El2H3njjDS1cuNCRP/DAA7rmmms0d+5cDR48WFdffbW2bt2q6dOnq0uXLtbPGzzrrLN04YUX6t5771VZWZkmT56sZs2aaezYsdVjpk2bpgsvvFDnnHOO7r77brVv314FBQXKzc3Vrl279Pnnnwec6+rVq3XJJZdowoQJP9lU4IorrtC3336rsWPHavny5Vq+fHn119LS0nTZZZe5+O7AC6J1DRQVFenFF1+UJK1YsUKSNHXqVCUnJys5OVkjR4508+1BlIvG+u/UqZM6depk/VpmZiZXoHGCaFwDkvSrX/1Kr732mrKzs7V582ZlZGTorbfe0vbt2/X++++7/wYhqkVr/bMP+JcwdASPesdb2we67dy50/j9fvPEE0+Ydu3amYSEBHP++eebDz74wAwbNsy0a9eu+ljHW9tPmjTJPPvss6Zt27YmISHBXHTRRebzzz93PPaWLVvMbbfdZtLT001cXJxp3bq1ueaaa8ycOXOqx9S2tf3Jzq1fv361+M4hWkT7Gjg+J9vt3+cOb4r2+rcRH3GFf+OFNVBQUGCGDRtmUlJSTEJCgundu7dZuHBhTb9liCLRXv/sA77nM+bffo8AAAAAAAAExN9EAwAAAADgEptoAAAAAABcYhMNAAAAAIBLbKIBAAAAAHCJTTQAAAAAAC6xiQYAAAAAwKUGdXXgadOmadKkScrPz1e3bt304osvqlevXj95P7/frz179qhJkyby+Xx1NT0gIGOMSkpK1KpVK8XE1Ox9pprWv8QaQHiFov4lngMQuXgOgJdR//CyoOq/Lj58+p133jHx8fHmjTfeMF988YW5++67TXJysikoKPjJ++7cufOkH+LNjdupuu3cufOU1z9rgFt9udW0/mu7Bqh/bvXlxnMANy/fqH9uXr65qX+fMcYoxHr37q2ePXtq6tSpkr5/V6lt27a6//779fDDD5/0vkVFRUpOTtaFukoNFBfqqQE/qVIVWq4FKiwsVFJSUtD3r039S6wBhFdt61/iOQCRjecAeBn1Dy8Lpv5D/uvc5eXlWrduncaNG1edxcTEaMCAAcrNzXWMLysrU1lZWfW/S0pK/jWxODXwsXgQBv96W6kmv0YUbP1LrAHUM7Wof4nnAEQBngPgZdQ/vCyI+g95Y7EDBw6oqqpKaWlpJ+RpaWnKz893jJ84caKSkpKqb23btg31lIBTJtj6l1gDiC48B8DLeA6Al1H/8JKwd+ceN26cioqKqm87d+4M95SAU4o1AC+j/uF1rAF4GfWPSBXyX+du3ry5YmNjVVBQcEJeUFCg9PR0x/iEhAQlJCSEehpAWARb/xJrANGF5wB4Gc8B8DLqH14S8ivR8fHx6t69uxYtWlSd+f1+LVq0SFlZWaF+OKBeof7hdawBeBn1Dy+j/uEldfI50aNHj9awYcPUo0cP9erVS5MnT9aRI0d0++2318XDAfUK9Q+vYw3Ay6h/eBn1D6+ok0300KFDtX//fo0fP175+fk677zztHDhQkejASAaUf/wOtYAvIz6h5dR//CKOvmc6NooLi5WUlKS+us6WtsjLCpNhZZqvoqKitS0adNT/visAYQT9Q+vYw3Ay6h/eFkw9V8nV6JRc+UftbPmS34235pXmCpHNmHf+UE95t9f6GvNm/91iyMzJd9Zx/qPHg3qMQEAANyKDfCC9sD1P3Nkzd/Ps46tOngopHMC4F1h/4grAAAAAAAiBZtoAAAAAABcYhMNAAAAAIBLbKIBAAAAAHCJTTQAAAAAAC7RnTtMGrRuZc3/60z3XbglyS+/I5uQui6oufz3HzZY89fHZjiyF/94nXVsmyc+DeoxAQCAd8U0amTN99/czZpfcM96a57Taooj65b5gHVsuwm8VgEQGlyJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFyiO3eY5F/dzpr3Tqiw5n02/GetH/Oqtl9Y8983/4c1vz1pmyMruvkj69i3Sy+z5i2foxMmosuBEVnWfN2jL1vz9jm/suYdsleFbE4AEGlKrjzHmq94zNlt+2Su2jTEkZ355h7r2MqgjgyERsx5XRzZt0OSrGM33jHVmp/z+khrnnDY58guuNn+qTvrXj3Pmjd7Ndea4+S4Eg0AAAAAgEtsogEAAAAAcIlNNAAAAAAALrGJBgAAAADAJTbRAAAAAAC4RHfuMEl7x94pe/DSm6x5yubNtX7MNc3SrHmvm++33+GyQ45oZY+3rEMfHPOlNe958W3WvNX/ON+/Mevs3xMgXBqkO9fM3x951jq2yiRa8w6ddod0ToDXNGjX1pp/9Xhza35DV2dn2s/OD+mUEKTKS7s7sjefs/8slRKsaZd37a9VOoxd63y8Svpwo/64ZvYnjuz2plusYyuM/Rjr73jB9ePF+WKtecEj9k/Yefj2a6z5vjHOTxLy5X7ueh7RjivRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFyisViYVBUX278QKA/FYx50NgqTpNSpn9rvMNUZXaue1qG//uYra76h59vWfNG7zsYhz9z2S+tY36c0MUB4HLi8vSM7Lcbe9GZ31VFrHnuvfXxVzacFRKVADcSazD5izddmvGvNB//qAUeWoDU1nxhc8/ezd3D73xnOpkgtY+OtY3/2J3sDsbMeWmnNA/RhAuqNP+1wvnaeUnSJdWzVrka1frxNN02z5ikx9jX3vxn/35rf8cwVjuxw35rPK9pwJRoAAAAAAJfYRAMAAAAA4BKbaAAAAAAAXGITDQAAAACAS2yiAQAAAABwie7cCIkH5g235ptutncI7NfQ2cl45DX2joSZAZqHA6ESc14Xaz77fyZZ0obWsf0+GG3NO25eXdNpAVGrQfszHFmvnM3WsQ83t39Cw7nL77HmZyygE3ddi22WYs2/G1dkzds0cH5KQZclI6xjA3XhBiJV05sPO7Im5QXWsf4j9k8jCEavrfYO9zPGPG/NO8b5av2YXsSVaAAAAAAAXGITDQAAAACAS2yiAQAAAABwiU00AAAAAAAusYkGAAAAAMAlunMjJM4M0E1zxtVtrfmwptsdWdK5B0M6J+DHGrRpbc3Pn/lPa57RwN6J26bjfXThBn4sUOf75+e/6sgyGyRax3Z8P9ue38OaC5fdt3ay5qvPecH1MZr/zf7/DUSbqsPO7tx1KXWq/WNtbtcoa77i4cnW/I60TxzZE1cPt45N+NB7n4rAlWgAAAAAAFxiEw0AAAAAgEtsogEAAAAAcIlNNAAAAAAALrGJBgAAAADAJbpzo07Nuy7Lmvvn+RzZn899wzr23va3WPPKb7fVeF7wpi0jMqz5X1q8b82L/WWO7LLHxljHNlNuzScGRLjyK3pa81demWzNz7R0vu82ZaR1bMen7J1mUfdiz8q05u+PfjrAPRKs6fh9zvpIfoufmcCp1HKJ/VNw4sbFWvNLGpY6st90iLOOTa/5tCIWV6IBAAAAAHCJTTQAAAAAAC6xiQYAAAAAwCU20QAAAAAAuBR0Y7GPP/5YkyZN0rp167R3717l5ORo0KBB1V83xmjChAl69dVXVVhYqL59++rll19Whw4dQjlvRAj/1p3WPGfv+Y7smg55dT2dWqP+I0NsWqo1n3nLVGvuD3CcW7cMcWTNXvVuMxzqv/7xJTgbOcW0a2MdW7V5S60fz3+R82e3JN31wlxrntkg0Zp3fdXZRCzj6fq/try2BvZc2dKat4x1NoY7mX8OPdOS1r4ecWp5rf69osJUuR9s6m4ekSboK9FHjhxRt27dNG3aNOvXn376aU2ZMkXTp0/XqlWr1LhxYw0cOFClpc4Ob0Ckof7hZdQ/vI41AC+j/oEfBH0l+sorr9SVV15p/ZoxRpMnT9bvf/97XXfddZKkWbNmKS0tTfPmzdNNN91Uu9kCYUb9w8uof3gdawBeRv0DPwjp30Rv3bpV+fn5GjBgQHWWlJSk3r17KzfX/mtaZWVlKi4uPuEGRKKa1L/EGkB0oP7hdawBeBn1D68J6SY6Pz9fkpSWlnZCnpaWVv21H5s4caKSkpKqb23btg3llIBTpib1L7EGEB2of3gdawBeRv3Da8LenXvcuHEqKiqqvu3caW9EBUQr1gC8jPqH17EG4GXUPyJV0H8TfTLp6emSpIKCArVs+UNHx4KCAp133nnW+yQkJCjB0l0U0eHQf3a35p90muLILtxwh3VsyrebQzqnulKT+pdYA3Vh1yvNrHn3AN/mDeX2/tyVv2luSffWcFbRjfoPTkzjxtb8WP8u1jx/mL0xz9Cz1zuytz5Pso7tcJvLyf1LTNdOjmzczDetY7MSy6z5eVMfsOZnvPCZI/ObyG77Go1roOjcCmvuD/iZBvCqaKz/aLP1P+yvjQKZ810rR5a6/liophPxQnolOjMzU+np6Vq0aFF1VlxcrFWrVikrKyuUDwXUO9Q/vIz6h9exBuBl1D+8Jugr0d99952++eab6n9v3bpVn332mVJSUpSRkaEHH3xQjz/+uDp06KDMzEw98sgjatWq1QmfIwdEKuofXkb9w+tYA/Ay6h/4QdCb6LVr1+qSSy6p/vfo0aMlScOGDdPMmTM1duxYHTlyRCNGjFBhYaEuvPBCLVy4UImJiaGbNRAm1D+8jPqH17EG4GXUP/CDoDfR/fv3lznJ3y35fD499thjeuyxx2o1MaA+ov7hZdQ/vI41AC+j/oEfhL07NwAAAAAAkSKk3bmBH2ueu9/12INbUqy5PQW+d3i4s2HJhp7TrGO/M+XWfOhCewfhjmtW13xiiFqxzew/lXyNGlnz7b/McGTDbv2bdezo0z+x5n7Zr/4c9ju7di97p491bCDlV/S05v2fWuHI+ibauzV3XHCfPZ/4qTWntzPCoUFrZ7dhScq/up01b3fLN45sw8ZM61if8Vnz0z93f72qQYDGx8lv5bo+BtAg017PNw5eFtRxFhw815HFfLKhRnOKRlyJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFyiOzfqVN49za35+H3ObrBn//Yz61i6uEKSfD3PsebXjl7i+hiP5F9szTveSxduOH39wgXWfOOQKdY8zhcbgke1d/jdW2Vv29vv7w86si6f77YfumW6/RhPf2zNf9PsS0d2/qrbrGM7jf7KmvPzO7Jd1DUvqPFXbRpizeO+3R6K6dTakXNbW/NPJ9jXtE3MmfbrT4uO2bvzxwy0r4J+DY86sgpTZR074UF7x/3lk3tbc7p5e1urdw5Y8982C66zdt7bnRxZquyfuOBFXIkGAAAAAMAlNtEAAAAAALjEJhoAAAAAAJfYRAMAAAAA4JLnGov54uKt+c6HejiyKXe9Yh17cWK5NY8J0BDGL+NydlLf34205vsvrHR9jMx37U0sEncWWfOqvG9cHzu2aVNrnvffXaz55htfsuYd5t3rzEpXuZ4HvGf/+DJrPs7S/Ghdub05y1cP/Mya+/RZjeeF6NWj+9fWPMFXd0+d9+y6yJpvG9PBmndcvtaRVQV4nst75Vxr/mHzhda8/0Znk6i2t2y1jvUfdTZJQuT7ZOPZ1jwmw97QcWHnHGt+XfsbHVnV5i32YzeyN+j69r+6WfMFt0xyZGc0sB/jsH+FNf/b0RbWfPR8ZyO9dgsqrGMbLF5nzffdZ28KdizNmbXsY28K+NbZb1vzJ59cY82vW+X++43o82pbe51XGHvzy8cP2J8bWs3f5sjc70aiH1eiAQAAAABwiU00AAAAAAAusYkGAAAAAMAlNtEAAAAAALjEJhoAAAAAAJc81507pn2GNV8/8gXXx7D3vpYCvSdxxabBjuy3Z/zVOjbptl3WfEWneQHmYpnNVfbZBXLOW7+25g33OruNH21t7zT+5Y1TrLk/wPck5TPev4HdgV9lWfPF5z9nzf1ydiK+ef791rFnrVhZ84nBc3a+ZO+Ifdev7Z/QcHNze31d0rDU9WNOb/OJNS97x94N+fwVdzmyynJ7B9YvLrF/WkKgzqyN7ne+RKiiC7enxBfYXyZaX3ucRGlGsiOL22wfe6yf/VMU/jHc/jpDSnAkzxyydxX/YMKl1rzRXPung5yp2j9npL70aa2PcfUDY6356rH216559zq7jZ81iu7ckSymcWNrnjexqyOrMPZO8YuO2bvWr7nZvuaqdgdYpJDElWgAAAAAAFxjEw0AAAAAgEtsogEAAAAAcIlNNAAAAAAALrGJBgAAAADAJc915zY791jzW7de4cjeylwY1LELqo5Z8+LSREc28v85O6pK0s1Xf2zNZxS3tebDmm53ObvAvrh1qjUPtvtmMO4a9RdHNveLAdaxvk8/r7N5IHwCdZpM/o/d1ryRz9mFW5KeOujsKnn2/9g7Sla5nBsgSU1n2zvz7pltHz+5qb2z/KhsZ/fUu29ZYB17f/K31jzOZ++4vfHCGfbJWNmPkRBTYc23P+HsetwooaN1bLNH7evTrN3ocm6oj9o/YX/+7dJuhDX/8tL/teYPT5/lyJ4beqN17Pb/sH8KSDA+vs7ebbjRt/Yu3PXd6ZvtazSQL2980ZFdO6pnqKaDMPhqSmdr/sVA5/91oJ/19y6+zZp3/HJNTaflaVyJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFzyXHdu/9Gj1nxbUWvXx7jqtnuseeLWg9Y85Vtnp+CUAMde82yaNf/rLy625s+e6cz8Z9q7hG/s92qARz31pr55nSNru369dWzd9QhHOOU96exYLEl5nV+y5psryq35R//lXBuJB1fXfGJADVUVF1vzNhM/dWR/nZhsHfvWr7Kt+eJHnrPmgbrWB2NoU3sHZn9H5/vsH/36IutYs9b+8xuRLdBrprazA7x8vNQe92voPE7rP79mHdskJtDnKDi7xQdy1QfrrPnrL15jzVu8nOv62HXp2KBe1vzscV8EdZzx++jEHalif3a2NX+tv/tPYuj72U3WvNOoL605r7NrhivRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFzyXGOxw8OzrPmK86Y6shnF7axjD3W2N7doucv+7Yw9+yyXswusvInPmo+5YZ4ju73pzgBHsb9nEiP7sYv8zkZO2yvjrGOTY+xNnwZvuNuat/l7kSPzl5ZaxyLyVQzo7sjWDXo+wGj7+rpm8f3WvOP7NBFD9Djct8yaxynWPt7v/Ll5wdwx1rGtPjHWvOkiZ/NLSVLLFo4o9ksaiEFK+Osaa/6zd+w/pz8bOtk5Nr6hdWyFCdRYzL17krZb890jVljzzxZ3rPVjBrLlNuc6kqTy1EpH9s1V061j/bKv3dwy+2uyjUPOsKTbrGMRHg3a2Bsa95i90ZpnJdibBts0einZmvuPfO36GPhpXIkGAAAAAMAlNtEAAAAAALjEJhoAAAAAAJfYRAMAAAAA4BKbaAAAAAAAXPJcd+4WS3ZZ80kHuziyMc3sHfKGjXvBmseMs78n4Zff5ewCiwnwfoft2ME+mq0LtyRd8Em2I+v4aIl1bEVaU2ve8pMN1tzeZxLR6sDIo46saUyidezuKudYSTr7JXv3dmoJ9V2D9DRHVvpHexf6rzu/Zs1v3TbQmheOSHVkHb5YGcTspIC9kA8fDuo4wJlj7LU3YMODjmz0+D9Zx35Tmm7NA70ms7O/ZpqQus4+fHGA3Hrkunut9+cjza3581sGWPOUu+wdmyt3b6v1XFC3mr1nfz39++b/CHAP+yc03LOznyNL+NDePR+hxZVoAAAAAABcYhMNAAAAAIBLbKIBAAAAAHCJTTQAAAAAAC4FtYmeOHGievbsqSZNmig1NVWDBg1SXl7eCWNKS0uVnZ2tZs2a6bTTTtOQIUNUUFAQ0kkD4cIagJdR//Ay6h9exxoAfhBUd+5ly5YpOztbPXv2VGVlpX73u9/p8ssv15dffqnGjRtLkkaNGqUPP/xQ7733npKSkjRy5Ehdf/31WrFiRZ2cQLAqt++05h/f3sORDZhj7wTZLT6kUzplXitqb81zsi+z5mcuWe/IAnVxjdlc01lFlmhYA3WpQZvW1nxxd2fHYb/s3bn7zx9jzTusXVXziSEkqP+a+WpspjPrPM069r3v7N15C+9oZs2rfvQCFnWH+q+5pD86u3a/+ekl1rGmqNiaf9TzYmu+5/YyRzbm3L9bxw5ruj3QFGtt1J6LrPmaggxrXvQP55ru8Npe69im326x5pUu5xYqrIGaiT39dEfWtIH9k0gqjP2V9i+3/MI+fpjtkx6+cz031FxQm+iFCxee8O+ZM2cqNTVV69at08UXX6yioiK9/vrrmj17ti699FJJ0owZM9S5c2etXLlSF1xwQehmDoQBawBeRv3Dy6h/eB1rAPhBrf4muqioSJKUkpIiSVq3bp0qKio0YMAPn2fXqVMnZWRkKDc313qMsrIyFRcXn3ADIgVrAF5G/cPLQlH/EmsAkYvnAHhZjTfRfr9fDz74oPr27auuXbtKkvLz8xUfH6/k5OQTxqalpSk/P996nIkTJyopKan61rZt25pOCTilWAPwMuofXhaq+pdYA4hMPAfA62q8ic7OztbGjRv1zjvv1GoC48aNU1FRUfVt50773ywD9Q1rAF5G/cPLQlX/EmsAkYnnAHhdUH8TfdzIkSP1wQcf6OOPP1abNm2q8/T0dJWXl6uwsPCEd6EKCgqUnp5uPVZCQoISEmx/FA/UX6wBeBn1Dy8LZf1LrAFEHp4DgCA30cYY3X///crJydHSpUuVmXlix9Hu3bsrLi5OixYt0pAhQyRJeXl52rFjh7KyskI36zpg1n3hyP67//XWseVv2I/xzRb7D4jfXrjAkd2etM069mdLR1jzqiP2/6r4Amd+5lv77BM8bP87k9j9zi7csIvmNRAMXwN7PVa+6bPmp8c0dGT7quydKc/6U2nNJ4Y6Rf2f3J6H+ljzvw952pGN2vNz69hvh59hzenCHX7Uf2hVfrstqPHxCw9Z8zMWOrN5aV2tY+cl1d3/g9lrf+2VUmL/+JIUS3aqu20HizVQM7uHd3Zkc1pODuoY5fcmWfOqbe4/Hid/lP056ru2ftfHaD/f2Q1fkmKWbXB9jGgR1CY6Oztbs2fP1vz589WkSZPqv29ISkpSw4YNlZSUpDvvvFOjR49WSkqKmjZtqvvvv19ZWVl05ENUYA3Ay6h/eBn1D69jDQA/CGoT/fLLL0uS+vfvf0I+Y8YMDR8+XJL0/PPPKyYmRkOGDFFZWZkGDhyol156KSSTBcKNNQAvo/7hZdQ/vI41APwg6F/n/imJiYmaNm2apk2bVuNJAfUVawBeRv3Dy6h/eB1rAPhBrT4nGgAAAAAAL6lRd26vqNxub7MfY+8Ho46yj89RC1eZJJ2p2v9hflWtjwCc3NeTeljzrzoFeufZ2XDs4tm/sY5s/2luTacFhFXrq7Zb8zs2/6cjS7ze3iTJX0IDMaC2qgoCNFgNlAN1qPXMTY5s7C8vso59uuUn1vye+R9Y86N+Z2fzOJ99J9A7cbk1T4mJt+abKpzZvWc7n88k6fRl1jiqcSUaAAAAAACX2EQDAAAAAOASm2gAAAAAAFxiEw0AAAAAgEtsogEAAAAAcInu3ACClnyWvbNwIPft7uvIOjz1lXUs3eURqcylu625re+pv26nAgCoJ6oOH3ZkhRXJQR1jQMNC12PjfLHWPLfsNGt+9Qv3WfPG+c5nqtPfXel6HtGOK9EAAAAAALjEJhoAAAAAAJfYRAMAAAAA4BKbaAAAAAAAXGITDQAAAACAS3TnBhC05r/YbM2vUfcA9zjmMgMAAIhu+/sUWvPB6nVqJyIpXZ+e8seMBlyJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFxiEw0AAAAAgEtsogEAAAAAcIlNNAAAAAAALrGJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFxiEw0AAAAAgEtsogEAAAAAcIlNNAAAAAAALrGJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX2EQDAAAAAOASm2gAAAAAAFxqEO4J/JgxRpJUqQrJhHky8KRKVUj6oRZPNdYAwon6h9exBuBl1D+8LJj6r3eb6JKSEknSci0I80zgdSUlJUpKSgrL40qsAYQX9Q+vYw3Ay6h/eJmb+veZcL3VFIDf79eePXvUpEkTlZSUqG3bttq5c6eaNm0a7qnVieLi4qg/RymyztMYo5KSErVq1UoxMaf+Lx5YA9Enks6R+j+1Iqk2aiOSzrO+rAFjjDIyMiLie1YbkVQbNRVJ51hf6p/ngOgRSecYTP3XuyvRMTExatOmjSTJ5/NJkpo2bVrvv+m15YVzlCLnPMPx7utxrIHoFSnnSP2fel44RylyzrM+rIHi4mJJkfM9qy0vnGeknGN9qH+J54BoEynn6Lb+aSwGAAAAAIBLbKIBAAAAAHCpXm+iExISNGHCBCUkJIR7KnXGC+coeec8Q80L3zfOEYF44fvmhXOUvHOeoeSV75kXztML51gXvPB94xwjV71rLAYAAAAAQH1Vr69EAwAAAABQn7CJBgAAAADAJTbRAAAAAAC4xCYaAAAAAACX6vUmetq0aTrjjDOUmJio3r17a/Xq1eGeUo19/PHH+sUvfqFWrVrJ5/Np3rx5J3zdGKPx48erZcuWatiwoQYMGKCvv/46PJOtoYkTJ6pnz55q0qSJUlNTNWjQIOXl5Z0wprS0VNnZ2WrWrJlOO+00DRkyRAUFBWGacf0WTfUvRf8aoP5DL5rWQLTXv8QaCDXqn/r3smiqf4k1cFw0rYF6u4l+9913NXr0aE2YMEHr169Xt27dNHDgQO3bty/cU6uRI0eOqFu3bpo2bZr1608//bSmTJmi6dOna9WqVWrcuLEGDhyo0tLSUzzTmlu2bJmys7O1cuVKffTRR6qoqNDll1+uI0eOVI8ZNWqU3n//fb333ntatmyZ9uzZo+uvvz6Ms66foq3+pehfA9R/aEXbGoj2+pdYA6FE/VP/XhZt9S+xBo6LqjVg6qlevXqZ7Ozs6n9XVVWZVq1amYkTJ4ZxVqEhyeTk5FT/2+/3m/T0dDNp0qTqrLCw0CQkJJg//elPYZhhaOzbt89IMsuWLTPGfH9OcXFx5r333qses2nTJiPJ5Obmhmua9VI0178x3lgD1H/tRPMa8EL9G8MaqA3qn/r3smiuf2NYA9GyBurllejy8nKtW7dOAwYMqM5iYmI0YMAA5ebmhnFmdWPr1q3Kz88/4XyTkpLUu3fviD7foqIiSVJKSookad26daqoqDjhPDt16qSMjIyIPs9Q81r9S9G5Bqj/mvPaGojG+pdYAzVF/VP/Xua1+pdYA5G6BurlJvrAgQOqqqpSWlraCXlaWpry8/PDNKu6c/ycoul8/X6/HnzwQfXt21ddu3aV9P15xsfHKzk5+YSxkXyedcFr9S9F3xqg/mvHa2sg2upfYg3UBvWv6n9H6vlS/zXntfqXWAORep4Nwj0BRKfs7Gxt3LhRy5cvD/dUgFOO+ofXsQbgZdQ/vM4La6BeXolu3ry5YmNjHd3aCgoKlJ6eHqZZ1Z3j5xQt5zty5Eh98MEHWrJkidq0aVOdp6enq7y8XIWFhSeMj9TzrCteq38putYA9V97XlsD0VT/Emugtqh/Vf87Es+X+q8dr9W/xBqI1POsl5vo+Ph4de/eXYsWLarO/H6/Fi1apKysrDDOrG5kZmYqPT39hPMtLi7WqlWrIup8jTEaOXKkcnJytHjxYmVmZp7w9e7duysuLu6E88zLy9OOHTsi6jzrmtfqX4qONUD9h47X1kA01L/EGggV6p/69zKv1b/EGojYNRDWtmYn8c4775iEhAQzc+ZM8+WXX5oRI0aY5ORkk5+fH+6p1UhJSYnZsGGD2bBhg5FknnvuObNhwwazfft2Y4wxTz75pElOTjbz5883//jHP8x1111nMjMzzbFjx8I8c/fuvfdek5SUZJYuXWr27t1bfTt69Gj1mHvuucdkZGSYxYsXm7Vr15qsrCyTlZUVxlnXT9FW/8ZE/xqg/kMr2tZAtNe/MayBUKL+qX8vi7b6N4Y1cFw0rYF6u4k2xpgXX3zRZGRkmPj4eNOrVy+zcuXKcE+pxpYsWWIkOW7Dhg0zxnzf3v6RRx4xaWlpJiEhwfz85z83eXl54Z10kGznJ8nMmDGjesyxY8fMfffdZ04//XTTqFEjM3jwYLN3797wTboei6b6Nyb61wD1H3rRtAaivf6NYQ2EGvVP/XtZNNW/MayB46JpDfiMMSY017QBAAAAAIhu9fJvogEAAAAAqI/YRAMAAAAA4BKbaAAAAAAAXGITDQAAAACAS2yiAQAAAABwiU00AAAAAAAusYkGAAAAAMAlNtEAAAAAALjEJhoAAAAAAJfYRAMAAAAA4BKbaAAAAAAAXGITDQAAAACAS/8HBi1UHJ1/N1UAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 5, figsize=(12, 4))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(x[i].squeeze().numpy())\n",
    "    axs[i].set_title(f\"Label: {y[i].item()}\")  # Use y[i] to get the corresponding label\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792b6d797ea94f50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.924941Z",
     "start_time": "2024-06-25T07:27:10.921206Z"
    }
   },
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernel, output_size):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_kernel, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=n_kernel, out_channels=n_kernel, kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=n_kernel * 4 * 4, out_features=50),\n",
    "            nn.Linear(50, 10),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227c10613ceeba15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:10.933366Z",
     "start_time": "2024-06-25T07:27:10.927099Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, perm=torch.arange(0, 784).long(), n_epochs=1):\n",
    "    model.train()    \n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "    # optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for i, (data, target) in enumerate(train_loader):\n",
    "            # send to device\n",
    "            data, targets = data.to(device), target.to(device)\n",
    "\n",
    "            # permute pixels\n",
    "            data = data.view(-1, 28*28)\n",
    "            data = data[:, perm]\n",
    "            data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "            # step\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(data)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f\"epoch={epoch}, step={i}: train loss={loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c92022d22750fa6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:25.767534Z",
     "start_time": "2024-06-25T07:27:10.935107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=6.422K\n",
      "epoch=0, step=0: train loss=2.2518\n",
      "epoch=0, step=100: train loss=0.2597\n",
      "epoch=0, step=200: train loss=0.3092\n",
      "epoch=0, step=300: train loss=0.2699\n",
      "epoch=0, step=400: train loss=0.2567\n",
      "epoch=0, step=500: train loss=0.2464\n",
      "epoch=0, step=600: train loss=0.2056\n",
      "epoch=0, step=700: train loss=0.0522\n",
      "epoch=0, step=800: train loss=0.0650\n",
      "epoch=0, step=900: train loss=0.1265\n"
     ]
    }
   ],
   "source": [
    "# ConvNet\n",
    "n_kernel = 6\n",
    "input_size = 28*28  \n",
    "output_size = 10\n",
    "convnet = ConvNet(input_size, n_kernel, output_size)\n",
    "convnet.to(device)\n",
    "print(f\"Parameters={sum(p.numel() for p in convnet.parameters())/1e3}K\")\n",
    "train(convnet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61fd3181c54ccc49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:25.773883Z",
     "start_time": "2024-06-25T07:27:25.768840Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, perm=torch.arange(0, 784).long()):\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, targets in test_loader:\n",
    "        # send to device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # permute pixels\n",
    "        data = data.view(-1, 28*28)\n",
    "        data = data[:, perm]\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        \n",
    "        # metrics\n",
    "        logits = model(data)\n",
    "        test_loss += F.cross_entropy(logits, targets, reduction='sum').item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == targets).sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(f\"test loss={test_loss:.4f}, accuracy={accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9dd4672c00151ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:27.660164Z",
     "start_time": "2024-06-25T07:27:25.775666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss=0.1326, accuracy=0.9605\n"
     ]
    }
   ],
   "source": [
    "test(convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54db7c5982a30303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:27.681165Z",
     "start_time": "2024-06-25T07:27:27.667825Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch import Tensor\n",
    "\n",
    "ts = \\\n",
    "    [\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 255, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 255, 255, 255, 255, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 255, 255, 255, 255, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 255, 255, 255, 255, 0, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0,0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 128, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 255, 255, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "\n",
    "\n",
    "img = np.array(ts, dtype=np.float32) / 255\n",
    "ts = tf(img)\n",
    "perm=torch.arange(0, 784).long()\n",
    "ts = ts.view(-1, 28*28)\n",
    "ts = ts[:, perm]\n",
    "ts = ts.view(-1, 1, 28, 28)\n",
    "ts = ts.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4e7e0424abc574c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:27.708457Z",
     "start_time": "2024-06-25T07:27:27.689931Z"
    }
   },
   "outputs": [],
   "source": [
    "convnet.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = convnet(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db7d7a7d0a2a168b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:27.782575Z",
     "start_time": "2024-06-25T07:27:27.709938Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.0626,  2.7084, -0.4546, -5.4904,  0.5802,  1.3416,  1.8292, -4.5070,\n",
      "          8.2102, -3.3943]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "preds = torch.argmax(y_pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b78ee792518149de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:27.788484Z",
     "start_time": "2024-06-25T07:27:27.783962Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14e0dad679d26f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:27:27.794493Z",
     "start_time": "2024-06-25T07:27:27.789625Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, n_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_hidden, output_size),\n",
    "            # nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# class ConvNet(nn.Module):\n",
    "#     def __init__(self, input_size, n_kernels, output_size):\n",
    "#         super().__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=n_kernels, kernel_size=5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Conv2d(in_channels=n_kernels, out_channels=n_kernels, kernel_size=5),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(n_kernels * 4 * 4, 50),\n",
    "#             nn.Linear(50, 10),\n",
    "#             # nn.Softmax(dim=-1)\n",
    "#         )\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, input_size, n_kernels, output_size):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.fc = nn.Linear(8 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 8 * 7 * 7)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "709cb87d1958a194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:28:59.437684Z",
     "start_time": "2024-06-25T07:28:59.431140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=8, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=8, out_features=8, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=8, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "mlp = MLP(input_size, 8, output_size)\n",
    "mlp.to(device)\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61211ba27ad398aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:29:18.052161Z",
     "start_time": "2024-06-25T07:29:05.592485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0, step=0: train loss=2.3514\n",
      "epoch=0, step=100: train loss=1.5070\n",
      "epoch=0, step=200: train loss=1.0717\n",
      "epoch=0, step=300: train loss=0.7944\n",
      "epoch=0, step=400: train loss=0.6417\n",
      "epoch=0, step=500: train loss=0.8709\n",
      "epoch=0, step=600: train loss=0.6959\n",
      "epoch=0, step=700: train loss=0.3601\n",
      "epoch=0, step=800: train loss=0.5998\n",
      "epoch=0, step=900: train loss=0.6249\n"
     ]
    }
   ],
   "source": [
    "train(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "59a13b410fc33a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:38:51.399799Z",
     "start_time": "2024-06-25T07:38:51.396152Z"
    }
   },
   "outputs": [],
   "source": [
    "def main(model):    \n",
    "    # Affichage du nombre de paramètres du modèle\n",
    "    print(f\"Parameters={sum(p.numel() for p in model.parameters())/1e3}K\")\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    train(model)\n",
    "    \n",
    "    # Évaluation du modèle sur le dataset de test\n",
    "    test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11c637dacda8204",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:39:13.631660Z",
     "start_time": "2024-06-25T07:38:59.079008Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=6.442K\n",
      "epoch=0, step=0: train loss=0.4474\n",
      "epoch=0, step=100: train loss=0.6269\n",
      "epoch=0, step=200: train loss=0.4198\n",
      "epoch=0, step=300: train loss=0.4779\n",
      "epoch=0, step=400: train loss=0.2998\n",
      "epoch=0, step=500: train loss=0.3376\n",
      "epoch=0, step=600: train loss=0.3194\n",
      "epoch=0, step=700: train loss=0.3119\n",
      "epoch=0, step=800: train loss=0.2253\n",
      "epoch=0, step=900: train loss=0.1436\n",
      "test loss=0.3865, accuracy=0.8880\n"
     ]
    }
   ],
   "source": [
    "main(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29ed0ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(1, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ConvNet\n",
    "n_kernel = 6\n",
    "input_size = 28*28  \n",
    "output_size = 10\n",
    "convnet = ConvNet(input_size, n_kernel, output_size)\n",
    "convnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32b1dd761e3535f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-25T07:39:35.968252Z",
     "start_time": "2024-06-25T07:39:21.343064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=4.266K\n",
      "epoch=0, step=0: train loss=2.3699\n",
      "epoch=0, step=100: train loss=0.3527\n",
      "epoch=0, step=200: train loss=0.2627\n",
      "epoch=0, step=300: train loss=0.1886\n",
      "epoch=0, step=400: train loss=0.1050\n",
      "epoch=0, step=500: train loss=0.1960\n",
      "epoch=0, step=600: train loss=0.1841\n",
      "epoch=0, step=700: train loss=0.0945\n",
      "epoch=0, step=800: train loss=0.1202\n",
      "epoch=0, step=900: train loss=0.1528\n",
      "test loss=0.1213, accuracy=0.9627\n"
     ]
    }
   ],
   "source": [
    "main(convnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f329c383",
   "metadata": {},
   "source": [
    "La précision du ConvNet (0.98) est nettement supérieure à celle du MLP (0.90), ce qui indique que le ConvNet est beaucoup plus efficace pour classer correctement les images.\n",
    "\n",
    "On note également que :\n",
    "- Le ConvNet montre des pertes d'entraînement beaucoup plus faibles et plus stables (entre 0.03 et 0.1) que le MLP (entre 0.29 et 0.7), ce qui suggère une meilleure capacité à minimiser l'erreur de prédiction.\n",
    "- Une perte de test plus faible dans le ConvNet (0.06), tandis que le MLP (0.35) montre une perte de test plus élevée, indiquant qu'il a plus de mal à généraliser.\n",
    "\n",
    "Cela s'exploque entre autre par le fait que dans le modèle ConvNet, le poids est partagé entre les différentes couches ce qui réduit le nombre de paramètres à apprendre, contrairement à MLP où le poids n'est pas partagé, complexifiant le modèle et l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede5019c1753fd8",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 7. Application d’un shuffle aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8988fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainWithRandomPerm(model):   \n",
    "    perm = torch.randperm(784)\n",
    "\n",
    "    # Affichage du nombre de paramètres du modèle\n",
    "    print(f\"Parameters={sum(p.numel() for p in model.parameters())/1e3}K\")\n",
    "    \n",
    "    # Entraînement du modèle\n",
    "    train(model, perm)\n",
    "    \n",
    "    # Évaluation du modèle sur le dataset de test\n",
    "    test(model, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1cf1e39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=6.442K\n",
      "epoch=0, step=0: train loss=2.8366\n",
      "epoch=0, step=100: train loss=0.7622\n",
      "epoch=0, step=200: train loss=0.5983\n",
      "epoch=0, step=300: train loss=0.3395\n",
      "epoch=0, step=400: train loss=0.5170\n",
      "epoch=0, step=500: train loss=0.5489\n",
      "epoch=0, step=600: train loss=0.4458\n",
      "epoch=0, step=700: train loss=0.3134\n",
      "epoch=0, step=800: train loss=0.2189\n",
      "epoch=0, step=900: train loss=0.3056\n",
      "test loss=0.3381, accuracy=0.9001\n"
     ]
    }
   ],
   "source": [
    "mainWithRandomPerm(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "02fb272b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters=4.266K\n",
      "epoch=0, step=0: train loss=4.4130\n",
      "epoch=0, step=100: train loss=1.0175\n",
      "epoch=0, step=200: train loss=0.6378\n",
      "epoch=0, step=300: train loss=0.7720\n",
      "epoch=0, step=400: train loss=0.6625\n",
      "epoch=0, step=500: train loss=0.7701\n",
      "epoch=0, step=600: train loss=0.2436\n",
      "epoch=0, step=700: train loss=0.3795\n",
      "epoch=0, step=800: train loss=0.5461\n",
      "epoch=0, step=900: train loss=0.5441\n",
      "test loss=0.3564, accuracy=0.8918\n"
     ]
    }
   ],
   "source": [
    "mainWithRandomPerm(convnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384e905",
   "metadata": {},
   "source": [
    "On remarque qu'en appliquant une permutation aléatoire, la précision du modèle ConvNet réduit fortement. C'est maitenant le modèle MLP qui offre une meilleure précision.\n",
    "\n",
    "Cela s'explique par le fait que la permutation aléatoire détruit la structure des données. Le modèle ConvNet ne peut donc plus reconnaître de motifs particuliers. Le MLP traite pixel par pixel, ses performances ne sont donc pas affectées par la permutation aléatoire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc188e5f",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 8. Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0eec1194",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "\n",
    "    print(f\"Le modèle a été sauvegardé à l'emplacement : {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8a1b499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a été sauvegardé à l'emplacement : ../model/mlp_model.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(mlp, \"../model/mlp_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aef4335f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le modèle a été sauvegardé à l'emplacement : ../model/convnet_model.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(convnet, \"../model/convnet_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3e72d6",
   "metadata": {},
   "source": [
    "___\n",
    "#### 3. 9. Conversion d’un notebook vers des fichiers sources"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
